{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBsGt8mB1fGc"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib .pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLo54LpO1fQ7"
      },
      "outputs": [],
      "source": [
        "gpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYYoje5K1fT-"
      },
      "outputs": [],
      "source": [
        "dataset = tfds.load(\"fashion_mnist\", split = \"train\")\n",
        "\n",
        "data_iterator = dataset.as_numpy_iterator()\n",
        "\n",
        "# Since we are not loading the entire dataset, we are only loading batches of the data to prevent saturating our memory.\n",
        "data_iterator.next()\n",
        "\n",
        "plt.figure(figsize = (6,6))\n",
        "\n",
        "for i in range(6):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    sample_img = data_iterator.next()\n",
        "    plt.imshow(np.squeeze(sample_img[\"image\"]))\n",
        "    plt.title(sample_img[\"label\"])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvr-Hm7C1fW5"
      },
      "outputs": [],
      "source": [
        "# We then create a function to normalize the images from 0-255 to 0-1\n",
        "\n",
        "def scale_imgs(data):\n",
        "    image = data[\"image\"]\n",
        "    return image/255\n",
        "\n",
        "# We can take the loaded data from tensorflow datasets and perfrom preprocessing.\n",
        "\n",
        "dataset = dataset.map(scale_imgs)\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(60000)\n",
        "dataset = dataset.batch(128)\n",
        "dataset = dataset.prefetch(64)\n",
        "\n",
        "dataset.as_numpy_iterator().next().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNVfz5Ac2u6c"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blvkhREN1fZq"
      },
      "outputs": [],
      "source": [
        "def generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    # input_dim is the latent space in which the images are generated\n",
        "    # the image is 7*7 * a random variable 128.\n",
        "    model.add(tf.keras.layers.Dense(7*7*128, input_dim=128))\n",
        "    model.add(tf.keras.layers.LeakyReLU(0.2))\n",
        "    model.add(tf.keras.layers.Reshape((7,7,128)))\n",
        "\n",
        "    # Upsampling block\n",
        "    model.add(tf.keras.layers.UpSampling2D())\n",
        "    model.add(tf.keras.layers.Conv2D(128, 5, padding = \"same\"))\n",
        "    model.add(tf.keras.layers.LeakyReLU(0.2))\n",
        "\n",
        "    # Upsampling block 2\n",
        "    model.add(tf.keras.layers.UpSampling2D())\n",
        "    model.add(tf.keras.layers.Conv2D(128, 5, padding = \"same\"))\n",
        "    model.add(tf.keras.layers.LeakyReLU(0.2))\n",
        "\n",
        "    # Convolutional block 1\n",
        "    model.add(tf.keras.layers.Conv2D(128, 4, padding = \"same\"))\n",
        "    model.add(tf.keras.layers.LeakyReLU(0.2))\n",
        "\n",
        "    # Convolutional block 2\n",
        "    model.add(tf.keras.layers.Conv2D(128, 4, padding = \"same\"))\n",
        "    model.add(tf.keras.layers.LeakyReLU(0.2))\n",
        "\n",
        "    # Add a convolutional layer to add the one  channel since image is 28,28,1.\n",
        "    model.add(tf.keras.layers.Conv2D(1, 4, padding = \"same\", activation = \"sigmoid\"))\n",
        "\n",
        "    return model\n",
        "\n",
        "generator = generator_model()\n",
        "\n",
        "generator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yx9hoG961fc4"
      },
      "outputs": [],
      "source": [
        "# Build the Discriminator model\n",
        "\n",
        "def discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation=\"LeakyReLU\", input_shape=[28,28,1]))\n",
        "    model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "    model.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"LeakyReLU\"))\n",
        "    model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "    model.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation=\"LeakyReLU\"))\n",
        "    model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "    model.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "    return model\n",
        "\n",
        "discriminator = discriminator_model()\n",
        "discriminator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IQDPYX11ffI"
      },
      "outputs": [],
      "source": [
        "from tensorflow .keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcgUdFtZ1fhw"
      },
      "outputs": [],
      "source": [
        "generator_optimizer = Adam(learning_rate=0.0001)\n",
        "discriminator_optimizer = Adam(learning_rate=0.00001)\n",
        "\n",
        "generator_loss = BinaryCrossentropy()\n",
        "discriminator_loss = BinaryCrossentropy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oor4NB6F1fkr"
      },
      "outputs": [],
      "source": [
        "class my_gan(Model):\n",
        "    def __init__(self, generator, discriminator, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.generator = generator\n",
        "        self.discriminator = discriminator\n",
        "\n",
        "    def compile(self, generator_optimizer, discriminator_optimizer, generator_loss, discriminator_loss, *args, **kwargs):\n",
        "        super().compile(*args, **kwargs)\n",
        "\n",
        "        self.generator_optimizer = generator_optimizer\n",
        "        self.discriminator_optimizer = discriminator_optimizer\n",
        "        self.generator_loss = generator_loss\n",
        "        self.discriminator_loss = discriminator_loss\n",
        "\n",
        "    def train_step(self, batch):\n",
        "        # Get the batch images of 128\n",
        "        real_images = batch # Here we get a batch of real images\n",
        "        fake_images = self.generator(tf.random.normal((128,128,1)), training=False)\n",
        "\n",
        "        # Lets first train the discriminator\n",
        "        with tf.GradientTape() as d_tape:\n",
        "            # This involves passing the real and fake images through the discriminator model\n",
        "            yhat_real = self.discriminator(real_images, training=True) #Training=True so that the dropout layers are activated\n",
        "            yhat_fake = self.discriminator(fake_images, training=True)\n",
        "            yhat_realfake = tf.concat([yhat_real, yhat_fake], axis=0) # combine the two above into one set of outputs\n",
        "\n",
        "            # Then we create labels( i.e zeros-->Real Images & ones--> Fake Images)\n",
        "            # These will be labels from the discriminator output\n",
        "            y_realfake = tf.concat([tf.zeros_like(yhat_real), tf.ones_like(yhat_fake)], axis=0)\n",
        "\n",
        "            # Then add some noise to the outputs\n",
        "            # The noise is injected into our TRUE outputs\n",
        "            real_noise = 0.5*tf.random.uniform(tf.shape(yhat_real))\n",
        "            fake_noise = -0.58*tf.random.uniform(tf.shape(yhat_fake))\n",
        "            y_realfake += tf.concat([real_noise, fake_noise], axis=0)\n",
        "\n",
        "            # Calculate the loss\n",
        "            total_discriminator_loss = self.discriminator_loss(y_realfake, yhat_realfake)\n",
        "\n",
        "        # backpropagation\n",
        "        discriminator_grad = d_tape.gradient(total_discriminator_loss, self.discriminator.trainable_variables)\n",
        "        self.discriminator_optimizer.apply_gradients(zip(discriminator_grad, self.discriminator.trainable_variables))\n",
        "\n",
        "\n",
        "        # We can then train the generator\n",
        "        with tf.GradientTape() as g_tape:\n",
        "            # We first generate some new images\n",
        "            generated_images = self.generator(tf.random.normal((128,128,1)), training=True)\n",
        "\n",
        "            # We then create the predicted labels\n",
        "            # Note in the discriminator, the real images are \"Zeros\". We want to trick the discriminator and provide \"Zeros\"\n",
        "            #for the generated images. Hence this will also help in calculating the loss.\n",
        "            predicted_labels = self.discriminator(generated_images, training=False)\n",
        "            # Training is false because we do not want the discriminator to learn while training the generator.\n",
        "            # The calculated loss is then given by:\n",
        "            total_generator_loss = self.generator_loss(tf.zeros_like(predicted_labels), predicted_labels)\n",
        "            # The calculated loss is actually the trickto training. This is because we are passing the generated labels as zeros\n",
        "            # in order to confuse the discriminator. Everytime a generated image is passed as \"real\" by the discriminator, it is\n",
        "            # rewarded.\n",
        "\n",
        "        # backpropagation\n",
        "        generator_grad = g_tape.gradient(total_generator_loss, self.generator.trainable_variables)\n",
        "        self.generator_optimizer.apply_gradients(zip(generator_grad, self.generator.trainable_variables))\n",
        "\n",
        "        return {\"discriminator_loss\":total_discriminator_loss, \"generator_loss\":total_generator_loss}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQb8Ms1w1ful"
      },
      "outputs": [],
      "source": [
        "# Create an instance of the \"my_gan\" Class.\n",
        "image_gan = my_gan(generator, discriminator)\n",
        "\n",
        "# We then compile the model by passing through the losses and optimizers.\n",
        "image_gan.compile(generator_optimizer, discriminator_optimizer, generator_loss, discriminator_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QfcSm9l5eM2"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import array_to_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vR6yquG5kxr"
      },
      "outputs": [],
      "source": [
        "hist = image_gan.fit(dataset, epochs=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MmB3cjB_yHB"
      },
      "outputs": [],
      "source": [
        "hist.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVgUL2N86Lau"
      },
      "outputs": [],
      "source": [
        "plt.suptitle(\"Total_Model_Loss\")\n",
        "plt.plot(hist.history[\"discriminator_loss\"], label=\"discriminator_loss\")\n",
        "plt.plot(hist.history[\"generator_loss\"], label=\"generator_loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJ6PGkPL_8XW"
      },
      "source": [
        "## Use trained generator to generate images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CP5G7Pl_12h"
      },
      "outputs": [],
      "source": [
        "Test_image = generator.predict(tf.random.normal((15, 128, 1)))\n",
        "Test_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvVwOTa2_1sp"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (6,6))\n",
        "\n",
        "for i, Test_image in enumerate(Test_image):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(Test_image)\n",
        "    plt.title(i)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpnjPQJWAPJr"
      },
      "source": [
        "## Save the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkDgKL3mAQqM"
      },
      "outputs": [],
      "source": [
        "# generator.save('generator.h5')\n",
        "# discriminator.save('discriminator.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKuN92jeAZ4T"
      },
      "source": [
        "## Load up saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OkzdapZAbHv"
      },
      "outputs": [],
      "source": [
        "# generator.load_weights(os.path.join('saved_model', 'generator.h5'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}